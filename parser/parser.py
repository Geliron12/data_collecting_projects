# -*- coding: utf-8 -*-
"""Parser.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fqIenYT6Oj1ZhJmqQSLF8uBBaeFv-_Vh
"""

from bs4 import BeautifulSoup as bs
import requests
from docx import Document as docxdoc
from docx.shared import Inches
from docx.opc.constants import RELATIONSHIP_TYPE as RT
from spire.doc import *
from spire.doc.common import *
from PyPDF2 import PdfReader
import re

def extract_links_from_text(text):
  url_extract_pattern = "https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b(?:[-a-zA-Z0-9()@:%_\\+.~#?&\\/=]*)"
  return re.findall(url_extract_pattern, text)

"""Получение ссылок"""

def get_links_url(url):
  result = requests.get(url)
  page = result.text
  doc = bs(page)
  links = [element.get('href') for element in doc.find_all('a')]
  return links

def get_text_url(url):
  result = requests.get(url)
  page = result.text
  doc = bs(page)
  return doc

"""Получение ссылок docx"""

def get_links_docx(file_path):
    document = docxdoc(file_path)
    rels = document.part.rels
    def iter_hyperlink_rels(rels):
        for rel in rels:
            if rels[rel].reltype == RT.HYPERLINK:
                yield rels[rel]._target
    return [now for now in iter_hyperlink_rels(rels)]

def get_text_docx(file_path):
    doc = docxdoc(file_path)
    fullText = []
    for para in doc.paragraphs:
        fullText.append(para.text)
    return '\n'.join(fullText)

"""Получение ссылок doc"""

def get_text_doc(file_path):
    # Create an object of the Document class
    document = Document()
    # Load a Word DOC file
    document.LoadFromFile('/content/ex.doc')
    document.SaveToFile('/content/TEMP.docx', FileFormat.Docx2016)
    document.Close()
    return get_text_docx('/content/TEMP.docx')[len('Evaluation Warning: The document was created with Spire.Doc for Python.\n'):]

def get_links_doc(file_path):
    return extract_links_from_text(get_text_doc(file_path))

"""Получение ссылок pdf"""

def get_links_pdf(file_path):
  ans = []
  with open(file_path, 'rb') as book:
      book_reader = PdfReader(book)
      page_list = book_reader.pages
      for i in range(len(page_list)):
        story_page = page_list[i]
        page_text = story_page.extract_text()
        url_extract_pattern = "https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b(?:[-a-zA-Z0-9()@:%_\\+.~#?&\\/=]*)"
        ans += re.findall(url_extract_pattern, str(page_text))
  return ans

def get_text_pdf(file_path):
  ans = ''
  with open(file_path, 'rb') as book:
      book_reader = PdfReader(book)
      page_list = book_reader.pages
      for i in range(len(page_list)):
        story_page = page_list[i]
        ans += story_page.extract_text()
  return ans